{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPjkDmn4EiLZpz6ricriZte"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Riassunto e Identificazione delle Attività dalla Trascrizione di un Meeting"],"metadata":{"id":"sFTJbwWdO7SS"}},{"cell_type":"code","source":["\"\"\"\n","Installazione librerie, gruppo langchain per gestire i prompt e input-output e così via\n","La scelta della libreria pdfplumber è ricaduta sul fatto che oltre a leggere bene il testo dei pdf, si comporta molto bene con pandas\n","e con le tabelle e immagini per i dati così che sia più completo\n","\"\"\"\n","!pip install langchain langchain-community langchain_groq\n","!pip install pdfplumber"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipbdTr1vXLIn","executionInfo":{"status":"ok","timestamp":1746519025863,"user_tz":-120,"elapsed":5840,"user":{"displayName":"Lorenzo Spalletta","userId":"05110359365784754626"}},"outputId":"967f480e-319c-4da0-9247-ead56653e0f7","collapsed":true},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n","Requirement already satisfied: langchain_groq in /usr/local/lib/python3.11/dist-packages (0.3.2)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n","Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n","Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.24.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.13.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n","Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n","Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n","Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n","Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n"]}]},{"cell_type":"markdown","source":["## Creazione di una funzione che pulisce il testo da stopword e numeri e poi lo tokenizza per migliorare l'elaborazione dei dati."],"metadata":{"id":"ReCrhMeHHsVC"}},{"cell_type":"code","source":["import nltk\n","import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')\n","\n","def clean_and_tokenize_text(text):\n","    \"\"\"\n","    Pulisce un testo rimuovendo numeri, stopwords italiane e restituisce i token.\n","    Args:\n","        text (str): Il testo da pulire.\n","    Returns:\n","        list: Lista di token puliti.\n","    \"\"\"\n","    # Rimuove i numeri\n","    text_no_numbers = re.sub(r'\\d+', '', text)\n","\n","    # Tokenizza il testo\n","    words = word_tokenize(text_no_numbers, language='italian')\n","\n","    # Carica le stopwords italiane\n","    stop_words = set(stopwords.words('italian'))\n","\n","    # Filtra: solo parole alfabetiche e non stopwords\n","    transcription_text = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n","\n","    return transcription_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRmG7RGYp05F","executionInfo":{"status":"ok","timestamp":1746519025905,"user_tz":-120,"elapsed":40,"user":{"displayName":"Lorenzo Spalletta","userId":"05110359365784754626"}},"outputId":"7d11a39f-b6fd-4f89-d5f8-8339b0a58cdc"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["#Altra funzione\n","\n","def clean_and_tokenize_text(text):\n","    \"\"\"\n","    Pulisce un testo rimuovendo numeri, stopwords italiane e restituisce i token.\n","    Args:\n","        text (str): Il testo da pulire.\n","    Returns:\n","        list: Lista di token puliti.\n","    \"\"\"\n","    text_no_numbers = re.sub(r'\\d+', '', text)\n","    words = word_tokenize(text_no_numbers, language='italian')\n","    stop_words = set(stopwords.words('italian'))\n","    cleaned_tokens = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n","    return cleaned_tokens"],"metadata":{"id":"AaT_di_-I7HG","executionInfo":{"status":"ok","timestamp":1746519025906,"user_tz":-120,"elapsed":0,"user":{"displayName":"Lorenzo Spalletta","userId":"05110359365784754626"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["#Try con una trascrizione recuperata da 'url'"],"metadata":{"id":"qLKSbdapq16G"}},{"cell_type":"markdown","source":["###In questo test con il modello, andremo a prendere la trascrizione del meeting si fa la pulizia del testo e la tokenizzazione, ho cercato di intercettare i vari casi di immissione della tipologia del file, se vengono messi entrambi o nessuno.\n","### Una volta elaborata e pulita la trascrizione si procede con la trascrizione del modello, e successivamente la preparazione del prompt, dando il contesto all'LLM e il formato desiderato in output.\n","###Infine si crea la catena che collega modello, prompt e template(che in questo caso sono già uniti) e si va a runnare il contenuto."],"metadata":{"id":"6Tb9zYfgJNnd"}},{"cell_type":"code","source":["import requests\n","import pdfplumber\n","import nltk\n","from langchain_groq import ChatGroq\n","from langchain.chains import LLMChain\n","from langchain.prompts import PromptTemplate\n","\n","\n","url = \"https://raw.githubusercontent.com/Profession-AI/progetti-llm/refs/heads/main/Riassunto%20e%20identificazione%20delle%20attivit%C3%A0%20dalla%20trascrizione%20di%20un%20meeting/meeting_transcription.txt\"\n","pdf = None\n","\n","transcription_text = \"\"\n","\n","#Caricamento testo\n","try:\n","    if url and not pdf:\n","        response = requests.get(url)\n","        response.raise_for_status()\n","        transcription_text = response.text.strip()\n","    elif pdf and not url:\n","        with pdfplumber.open(pdf) as pdf_file:\n","            transcription_text = \"\\n\".join(\n","                page.extract_text() for page in pdf_file.pages if page.extract_text()\n","            ).strip()\n","        if not transcription_text:\n","            raise ValueError(\"Il pdf non ha testo leggibile all'interno\")\n","    else:\n","        raise ValueError(\"Per favore inserisci solo una tra le due opzioni: url o pdf\")\n","except Exception as e:\n","    print(f\"Errore durante il caricamento: {e}\")\n","    transcription_text = \"\"\n","\n","#Se si ha il testo\n","if transcription_text:\n","    # Pulizia e tokenizzazione\n","    cleaned_tokens = clean_and_tokenize_text(transcription_text)\n","    cleaned_text = ' '.join(cleaned_tokens)\n","\n","    # Configura il modello LLaMA tramite Groq\n","    llm = ChatGroq(\n","        api_key='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',\n","        model='llama3-70b-8192'\n","    )\n","\n","    # Prepara il prompt\n","    prompt_goal = PromptTemplate(\n","        input_variables=[\"transcription\"],\n","        template=\"\"\"\n","Sei un assistente per uffici esperto. Leggi la seguente trascrizione di un meeting e produci:\n","- Un riassunto diviso nei punti chiave discussi durante il meeting\n","- Per ogni persona del meeting crea un elenco dove ci sono i compiti che deve svolgere o supervisionare.\n","\n","\n","Trascrizione:\n","{transcription}\n","\n","Rispondi SOLO nel formato:\n","---\n","Riassunto:\n","- Punto 1\n","- Punto 2\n","...\n","\n","Attività:\n","- Persona A: attività\n","- Persona B: attività\n","...\n","---\n","\"\"\"\n","    )\n","\n","    # Crea la catena LLM\n","    output = LLMChain(llm=llm, prompt=prompt_goal)\n","\n","    # Esegui la catena\n","    try:\n","        result = output.run({\"transcription\": cleaned_text})\n","        if \"---\" in result:\n","            blocks = result.split('---')\n","            clean_output = blocks[1].strip() if len(blocks) > 1 else result\n","            print(clean_output)\n","        else:\n","            print(result)\n","    except Exception as e:\n","        print(f\"Errore durante l'elaborazione dell'output: {e}\")\n","else:\n","    print(\"Nessuna trascrizione valida disponibile per l'elaborazione.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVy7gZorq3Es","executionInfo":{"status":"ok","timestamp":1746519027407,"user_tz":-120,"elapsed":1500,"user":{"displayName":"Lorenzo Spalletta","userId":"05110359365784754626"}},"outputId":"66e09fff-b397-4e85-aba0-bf3355b6b084"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Riassunto:\n","- Requisiti del nuovo sistema contabile: intuitività, gestione automatizzata, reportistica personalizzabile, modulo per filtri e grafici, automazione scadenze con notifiche promemoria, archiviazione digitale di documenti con funzione di ricerca avanzata.\n","- Richiesta di creazione di un piano tecnico basato sui requisiti emersi e approvazione del progetto definitivo.\n","\n","Attività:\n","- Rossana Bolletta: nulla (ha già espresso le esigenze)\n","- Mario Rossi: supervisionare il progetto e approvare il piano tecnico\n","- Andrea Monti: creare un piano tecnico basato sui requisiti emersi, implementare la gestione delle notifiche e della posta elettronica, configurare il server SMTP, utilizzare una libreria per l'archiviazione digitale dei file, implementare la funzione di ricerca dei documenti.\n"]}]},{"cell_type":"markdown","source":["###Il risultato che si ottiene è qualitativamente buono. Per la lunghezza della trascrizione risulta essere un pò troppo verboso in quanto non riesce a sintetizzare in maniera concisa i concetti, dando però la panoramica completa di ogni punto saliente. Per quanto riguarda il secondo punto scende leggermente di qualità di output. Per quanto riguarda Andrea si riscontra un ottimo lavoro di assegnazione delle mansioni, mentre su Mario Rossi potrebbero essere riassunti in uno o due punti o meno. Su Rossana non la riconosce come client e gli assegna compiti come fosse parte del team."],"metadata":{"id":"kBW4IYI5LymJ"}},{"cell_type":"markdown","source":["#Test con l'utilizzo di un file pdf\n","### Qui vado a caricare un file che riprende la trascizione di un intervista alla Protezione Civile utilizzando pressochè lo stesso script. Questo perchè il codice è modulare e quindi si presta a diverse situazioni."],"metadata":{"id":"D2IwGJuIsZbE"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Percorso completo al file (adatta se hai usato un'altra cartella)\n","file_path = '/content/drive/MyDrive/Project_llms/try3.pdf'\n","\n","# Esempio: leggi il file (qui solo per verificare che esista)\n","import os\n","if os.path.exists(file_path):\n","    print('File trovato!')\n","else:\n","    print('File NON trovato!')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"wQNmqt5RqVKd","executionInfo":{"status":"error","timestamp":1746519683238,"user_tz":-120,"elapsed":42688,"user":{"displayName":"Lorenzo Spalletta","userId":"05110359365784754626"}},"outputId":"10cab043-099c-40fe-d78d-4c5349d458d8"},"execution_count":16,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-3bf851d8840b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Percorso completo al file (adatta se hai usato un'altra cartella)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Project_llms/try3.pdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["def clean_and_tokenize_text(text):\n","    text_no_numbers = re.sub(r'\\d+', '', text)\n","    words = word_tokenize(text_no_numbers, language='italian')\n","    stop_words = set(stopwords.words('italian'))\n","    cleaned_tokens = [word.lower() for word in words if word.isalpha() and word.lower() not in stop_words]\n","    return cleaned_tokens\n","\n","url = None\n","pdf = file_path\n","\n","transcription_text = \"\"\n","\n","try:\n","    if url and not pdf:\n","        response = requests.get(url)\n","        response.raise_for_status()\n","        transcription_text = response.text.strip()\n","    elif pdf and not url:\n","        with pdfplumber.open(pdf) as pdf_file:\n","            transcription_text = \"\\n\".join(\n","                page.extract_text() for page in pdf_file.pages if page.extract_text()\n","            ).strip()\n","        if not transcription_text:\n","            raise ValueError(\"Il pdf non ha testo leggibile all'interno\")\n","    else:\n","        raise ValueError(\"Per favore inserisci solo una tra le due opzioni: url o pdf\")\n","except Exception as e:\n","    transcription_text = \"\"\n","    print(f\"Errore durante il caricamento: {e}\")\n","\n","if transcription_text:\n","    cleaned_tokens = clean_and_tokenize_text(transcription_text)\n","    cleaned_text = ' '.join(cleaned_tokens)\n","\n","    llm = ChatGroq(\n","        api_key='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',\n","        model='llama3-70b-8192'\n","    )\n","\n","    prompt_goal = PromptTemplate(\n","        input_variables=[\"transcription\"],\n","        template=\"\"\"\n","Sei un assistente per uffici esperto. Leggi la seguente trascrizione di un meeting e produci:\n","- Un riassunto diviso nei punti chiave discussi durante il meeting\n","- Crea per ogni persona un elenco di attività da svolgere o supervisionare, con indicazione della persona responsabile.\n","\n","Trascrizione:\n","{transcription}\n","\n","Rispondi SOLO nel formato:\n","---\n","Riassunto:\n","- Punto 1\n","- Punto 2\n","...\n","\n","Attività:\n","- Persona A: attività\n","- Persona B: attività\n","...\n","---\n","\"\"\"\n","    )\n","\n","    output = LLMChain(llm=llm, prompt=prompt_goal)\n","\n","    try:\n","        result = output.run({\"transcription\": cleaned_text})\n","        if \"---\" in result:\n","            clean_output = result.split('---')[1].strip()\n","            print(clean_output)\n","        else:\n","            print(result)\n","    except Exception as e:\n","        print(f\"Errore durante l'elaborazione dell'output: {e}\")\n","else:\n","    print(\"Nessuna trascrizione valida disponibile per l'elaborazione.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyyRrOaisc3k","executionInfo":{"status":"ok","timestamp":1746519041784,"user_tz":-120,"elapsed":14375,"user":{"displayName":"Lorenzo Spalletta","userId":"05110359365784754626"}},"outputId":"da04dab0-9ee3-44da-a404-a37989dbf11d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n","WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"]},{"output_type":"stream","name":"stdout","text":["Riassunto:\n","- La protezione civile italiana è un sistema complesso che coinvolge diverse forze e organizzazioni, tra cui i vigili del fuoco, i volontari e le autorità regionali e nazionali.\n","- La gestione dei cambiamenti climatici è una delle principali sfide per la protezione civile, richiedendo l'analisi di dati e la previsione di eventi estremi.\n","- La comunicazione e la consapevolezza dei cittadini sono fondamentali per la prevenzione e la gestione delle emergenze.\n","- La tecnologia deve essere aggiornata e integrata nei processi esistenti per migliorare l'efficacia della protezione civile.\n","- La formazione e l'educazione civica sono essenziali per promuovere comportamenti corretti e preparare le persone alle emergenze.\n","\n","Attività:\n","- Elisa Spalletta: analizzare i dati raccolti durante l'intervista e identificare gli ostacoli e le criticità nella gestione delle emergenze.\n","- Matilda Pacanowski: documentare la conversazione e identificare i punti chiave della protezione civile italiana.\n","- Dirigente della Protezione Civile: coordinare le attività delle diverse forze e organizzazioni coinvolte nella protezione civile.\n","- Cittadini: essere consapevoli dei rischi e partecipare attivamente alla gestione delle emergenze.\n","- Enti pubblici: migliorare la comunicazione e la trasparenza per aumentare la fiducia dei cittadini.\n","- Funzionari pubblici: lavorare per migliorare la coordinazione e la gestione delle emergenze.\n","- Ricercatori: analizzare i dati e sviluppare nuove tecnologie per migliorare la gestione delle emergenze.\n"]}]},{"cell_type":"markdown","source":["###In questo caso il modello si comporta decisamente meglio del test precedente. Il testo è molto più lungo (sono 7 pagine di intervista in cu iogni paragrafo è un pezzo di conversazione tra intervistato e intervistatore). I punti vengono riassunti in maniera ottima tralasciando cosa è superfluo. Anche il riconoscimento delle attività dei diversi enti è suddiviso correttamente."],"metadata":{"id":"GOGInM0dOLzZ"}},{"cell_type":"markdown","source":["#<font color=red>Limitazioni</font>\n","\n","\n","\n"],"metadata":{"id":"fDFk_7qbPNLl"}},{"cell_type":"markdown","source":["##Le limitazioni di questo modello sono principalmente 2. La prima che beneficiando di una velocità di esecuzione abbastanza alta potrebbe inficiare sulla qualità della comprensione del testo in sè portando ad omissioni o storpiature di alcuni temi simili o aggregare sottotemi che dovrebbero essere divisi. La seconda è collegata alla brevità che si crea nella creazione dei punti, portando a volte a delle troncature un pò brusche.\n"],"metadata":{"id":"hNnt8ZgQPpv3"}},{"cell_type":"markdown","source":["#**<font color=green>Conclusioni</font>**\n","#Il risultato del modello mi sembra comunque buono andando a superare tranquillamente i due test"],"metadata":{"id":"8y6YU-11Qehg"}},{"cell_type":"markdown","source":[],"metadata":{"id":"gV5FHKCrQeeF"}}]}